{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ingest-from-amazon-s3-to-nosql-table-using-v3io-frames-n-pandas\"></a>\n",
    "#### Ingesting Data \n",
    "https://github.com/v3io/frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /User/examples # <=> /v3io/${V3IO_HOME}/examples or /v3io/users/${V3IO_USERNAME}/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "CSV_PATH=\"/User/examples/stocks.csv\"\n",
    "curl -L \"iguazio-sample-data.s3.amazonaws.com/2018-03-26_BINS_XETR08.csv\" > ${CSV_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use V3IO Frames to convert the CSV file that was ingested in the AWS S3 data-collection example to a NoSQL table.\n",
    "# NOTE: Make sure to first create a V3IO Frames service from the \"Services\" page of the platform dashboard, and run the\n",
    "# \"Ingesting Files from Amazon S3 to the Platform File System Using curl\" example to create users/$V3IO_USERNAME/examples/stocks.csv.\n",
    "import pandas as pd\n",
    "import v3io_frames as v3f\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a V3IO Frames client for the \"users\" data container\n",
    "client = v3f.Client(\"framesd:8081\", container=\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full CSV file path\n",
    "csv_path = os.path.join(\"/User\", \"examples\", \"stocks.csv\")\n",
    "# Relative NoSQL table path within the \"users\" container\n",
    "rel_nosql_table_path = os.path.join(os.getenv('V3IO_USERNAME'), \"examples\", \"stocks_example_tab\")\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(csv_path, header=\"infer\")\n",
    "\n",
    "# Convert the CSV file to a NoSQL table\n",
    "client.write(\"kv\", rel_nosql_table_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Presto to query the NoSQL table that was created in the previous step\n",
    "presto_nosql_table_path = os.path.join('v3io.users.\"' + os.getenv('V3IO_USERNAME'), 'training/data/examples', 'stocks_example_tab\"')\n",
    "%sql select * from $presto_nosql_table_path limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example\"></a>\n",
    "## Data Collection and Exploration Getting-Started Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "DIR_PATH=\"/User/examples/\" # <=> \"/v3io/${V3IO_HOME}/examples/\" or \"/v3io/users/${V3IO_USERNAME}/examples/\"\n",
    "CSV_PATH=\"${DIR_PATH}stocks.csv\"\n",
    "\n",
    "# Create the examples directory\n",
    "mkdir -p ${DIR_PATH}\n",
    "\n",
    "# Download a sample stocks CSV file from the Iguazio sample data-set Amazon S3 bucket to the examples directory\n",
    "curl -L \"iguazio-sample-data.s3.amazonaws.com/2018-03-26_BINS_XETR08.csv\" > ${CSV_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-convert-csv-to-nosql-table\"></a>\n",
    "### Convert the Sample CSV File to a NoSQL Table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example diretory path - a <running user>/examples directory in the \"users\" container\n",
    "dir_path = os.path.join('/User/', \"examples\")\n",
    "# CSV file path\n",
    "csv_path = os.path.join(dir_path, \"stocks.csv\")\n",
    "# NoSQL table path\n",
    "nosql_table_path = os.path.join(dir_path, \"stocks_tab\")\n",
    "\n",
    "\n",
    "# Read the sample CSV file into a Spark DataFrame, and let Spark infer the schema of the data\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Show the DataFrame data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame data to a NoSQL table in a platform data container.\n",
    "# Define the \"ISIN\" column (attribute) as the table's primary key.\n",
    "client.write('kv',nosql_table_path,dfs=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-run-sql-queries\"></a>\n",
    "### Step 3: Run Interactive SQL Queries\n",
    "\n",
    "Use the `%sql` Jupyter magic to run an SQL queries on the \"stocks_tab\" table that was created in the previous step.\n",
    "(The queries is processed using Presto.)\n",
    "The example runs a `SELECT` query that reads the first ten table items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_nosql_table_path = os.path.join('v3io.users.\"' + os.getenv('V3IO_USERNAME'), 'examples', 'stocks_example_tab\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from $presto_nosql_table_path limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = %sql select securitydesc,count(*) as cnt from $presto_nosql_table_path group by securitydesc limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = client.read('kv',nosql_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = client.read('kv',nosql_table_path,filter='TradedVolume > 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-convert-data-to-parquet\"></a>\n",
    "### Convert the Data to a Parquet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame data that was read from the CSV file in Step 2 to a Parquet table in a platform data container\n",
    "prqt_table_path = os.path.join(dir_path,\"stocks_prqt\")\n",
    "df.to_parquet(prqt_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
